{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal example of lightning-crossval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.10.14\n",
      "IPython version      : 8.24.0\n",
      "\n",
      "lightning_cv: 0.5.0\n",
      "torch       : 2.2.2\n",
      "lightning   : 2.2.4\n",
      "pydantic    : 2.0.3\n",
      "sklearn     : 1.4.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -vp lightning_cv,torch,lightning,pydantic,sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seed everything for reproducibility\n",
    "from lightning import seed_everything\n",
    "seed_everything(111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lightning-crossval` was concurrently developed with the [`Protein Set Transformer`](https://github.com/AnantharamanLab/protein_set_transformer/), so the most thorough example is in that repository. \n",
    "\n",
    "This package is very opinionated and integrateed with `PyTorch-Lightning` (more specifically the `Lightning Fabric` subset) and requires the following things: \n",
    "\n",
    "1. All models used are subclasses of `lightning.LightningModule`\n",
    "2. All models take only a single argument to their `__init__` method called `config`, which is a subclass of `pydantic.BaseModel`. You should become familiar with Pydantic [here](https://docs.pydantic.dev/2.0/usage/models/).\n",
    "    - This object should hold all the necessary arguments to setup the model. [Here](https://github.com/AnantharamanLab/protein_set_transformer/blob/main/src/pst/nn/config.py) is a real example from the PST model.\n",
    "    - One of the fields of this config must be called `fabric`, which holds the reference to the `lightning.Fabric` object that is used to do all the magic.\n",
    "        - We have provided a simple Pydantic model called `BaseModelConfig` that can be subclassed to provide this\n",
    "\n",
    "-----\n",
    "\n",
    "Let's start with a simple toy example. We are going to create a simple binary classifier that uses scaled dot product multihead self-attention.\n",
    "\n",
    "## Model Config\n",
    "\n",
    "First, we need to create the model config that has all the fields to setup the underlying components, such as the size of feed forward linear layers, number of layers, and number of attention heads.\n",
    "\n",
    "NOTE: If you want to customize each field of the config, you can set the values to `pydantic.Field`, which takes many customization arguments, including default values, min/max values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning_cv import BaseModelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConfig(BaseModelConfig):\n",
    "    num_layers: int\n",
    "    hidden_size: int\n",
    "    num_heads: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "\n",
    "Now let's define our simple classifier that MUST subclass the `lightning.LightningModule`. See the lightning [tutorial](https://lightning.ai/docs/pytorch/LTS/common/lightning_module.html) for all the ways to customize your model.\n",
    "\n",
    "We provided a mixin class to handle some internal details related PyTorch Lightning and Lightning Fabric called `CrossValModuleMixin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from lightning import LightningModule\n",
    "from lightning_cv import CrossValModuleMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(CrossValModuleMixin, LightningModule):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        # need to init separately since CrossValModuleMixin needs the config\n",
    "        LightningModule.__init__(self)\n",
    "        CrossValModuleMixin.__init__(self, config=config)\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        ####### NN parts\n",
    "        self.encoder = torch.nn.TransformerEncoder(\n",
    "            torch.nn.TransformerEncoderLayer(\n",
    "                d_model=config.hidden_size,\n",
    "                nhead=config.num_heads,\n",
    "                batch_first=True,\n",
    "            ),\n",
    "            num_layers=config.num_layers,\n",
    "        )\n",
    "        self.classifier = torch.nn.Linear(config.hidden_size, 1)\n",
    "        ####### NN parts\n",
    "\n",
    "        # binary cross entropy loss for binary classification\n",
    "        self.objective_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # this is required by pytorch lightning\n",
    "    def configure_optimizers(self):\n",
    "        # can define however you want\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def forward_step(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.encoder(x)\n",
    "        return self.classifier(out).squeeze()\n",
    "\n",
    "    def forward(self, batch: dict[str, torch.Tensor], stage: str):\n",
    "        x, y = batch[\"x\"], batch[\"y\"]\n",
    "        pred = self.forward_step(x)\n",
    "\n",
    "        loss = self.objective_fn(pred, y.float().squeeze())\n",
    "        \n",
    "        if self.config.fabric is None:\n",
    "            self.log(\n",
    "                f\"{stage}_loss\", \n",
    "                loss,\n",
    "                prog_bar=True,\n",
    "                logger=True,\n",
    "                on_step=True,\n",
    "                on_epoch=True,\n",
    "            )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch: dict[str, torch.Tensor], batch_idx: int):\n",
    "        return self(batch, stage=\"train\")\n",
    "    \n",
    "    def validation_step(self, batch: dict[str, torch.Tensor], batch_idx: int):\n",
    "        return self(batch, stage=\"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datamodule\n",
    "\n",
    "Now to load data, you will need a custom subclass of `lightning.LightningDataModule` that implements your cross validation strategy. An additional requirement of your datamodule is that it **MUST** have the method `train_val_dataloaders` which returns an iterator with a tuple of 2  `torch.utils.data.DataLoader` objects. These dataloaders represent the training and validation dataloaders, respectively.\n",
    "\n",
    "We have provided a base class `CrossValidationDataModule` that handles these details and takes as input a cross validation object, such as those provided by the `scikit-learn` library.\n",
    "\n",
    "We are going to use a grouped k-folds cross validation scheme, but you can define your own custom cross validation splitters that have a `.split` method. Alternatively, you can use pre-existing splitters from `scikit-learn`, which is what we do here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from lightning_cv import CrossValidationDataModule\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "First, we need a `torch.utils.data.Dataset`. We are going to use a simple setup where our total dataset is stored as in a single tensor of shape `[Num individual datapoints, embedding dim]`, along with a separate tensor for the binary labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, x: torch.Tensor, y: torch.Tensor, groups: torch.Tensor | None = None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.groups = groups\n",
    "\n",
    "        assert x.shape[0] == y.shape[0]\n",
    "        assert y.ndim == 1\n",
    "\n",
    "        if groups is not None:\n",
    "            assert x.shape[0] == groups.shape[0]\n",
    "            assert groups.ndim == 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"x\": self.x[idx],\n",
    "            \"y\": self.y[idx],\n",
    "            \"groups\": self.groups[idx] if self.groups is not None else None,\n",
    "        }\n",
    "    \n",
    "    # this is needed since all CV splitters will return indices of each fold\n",
    "    # rather than the actual data itself\n",
    "    def collate_fn(self, batch: list[torch.Tensor] | torch.Tensor) -> dict[str, torch.Tensor]:\n",
    "        if isinstance(batch, list):\n",
    "            batch = torch.tensor(batch)\n",
    "\n",
    "        return self[batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "hidden_dim = 128\n",
    "x = torch.randn(batch_size, hidden_dim)\n",
    "y = torch.cat((\n",
    "    torch.zeros(batch_size // 2),\n",
    "    torch.ones(batch_size // 2),\n",
    ")).long()\n",
    "groups = torch.randint(0, 3, (batch_size,))\n",
    "\n",
    "dataset = SimpleDataset(x, y, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 1, 2, 0, 0, 0, 1, 0, 0, 2, 0, 1, 2, 0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the provided `CrossValidationDataModule` and be generally fine, but you can also subclass this and implement more custom functionality specific to your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = CrossValidationDataModule(\n",
    "    dataset=dataset,\n",
    "    batch_size=4,\n",
    "    cross_validator=GroupKFold,\n",
    "    cross_validator_config={\"n_splits\": groups.max().item() + 1},\n",
    "    group_attr=\"groups\",\n",
    "    collate_fn=dataset.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Trainer\n",
    "Now let's put it all together. You can perform cross validation with a `CrossValidationTrainer`. It accepts 2 arguments as input:\n",
    "\n",
    "1. `model_type`: your model's type, NOT an instance. These need to be setup for each fold\n",
    "2. `config`: a `CrossValidationTrainerConfig`, the arguments are mostly sent to `lightning.Fabric`\n",
    "\n",
    "NOTE: The strategy of this package is to load separate models for each fold (meaning each model is in memory) to keep each fold synchronized at the epoch level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning_cv import CrossValidationTrainer, CrossValidationTrainerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_cfg = CrossValidationTrainerConfig(max_epochs=5)\n",
    "cv_trainer = CrossValidationTrainer(\n",
    "    model_type=BinaryClassifier,\n",
    "    config=trainer_cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a model config so that the model for each fold has the same setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = ModelConfig(\n",
    "    num_layers=2,\n",
    "    hidden_size=hidden_dim,\n",
    "    num_heads=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you just need to call the `.train_with_cross_validation` method with the model config and cross validation data module.\n",
    "\n",
    "This will train a model for each fold and automatically checkpoint to `./checkpoints` with the pytorch checkpoints and the logged train/val performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fa0ad7db254a36894fed2374319b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  | Name            | Type             | Params\n",
      "-----------------------------------------------------\n",
      "0 | _forward_module | BinaryClassifier | 1.2 M \n",
      "-----------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.745     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4bf546cdeb1443db6aeeb244b3ea7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b70d7803b3444cd8fe6f74ff4171282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f508bf49634dc0adfa56a2327a754a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ca4a55579b44dbae5fe0c8dc9b3af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd87867c43b437db16f83f006db7b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1f306392cf4c2aa458a35ac6579cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da41c2493e54b5c9046b69d0807b522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b77144e62c5453cad03995394c3e039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380db5148ace4eafa7728812c017eec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4340029ece48a8a8d9ecdaa0f4d2ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f31acbd71dc4f83a82f263522c7ad24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba0d1de28444b56a3fe881f3c9b8b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75dd3021e294f5588cd5b95a177954e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468562cd671142ea8c85482f60781d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b357a8a63a904bc38480c017265426a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMPLETE: Training 5 epochs completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_trainer.train_with_cross_validation(data_module, model_config=model_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trainer still holds the trained models, which you can access through the `.fold_manager` dictionary.\n",
    "\n",
    "For this toy demo, we can compute the accuracy of the problem, expecting a relatively high accuracy for this fake classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.8125, 0.8750, 0.8125]), tensor(0.8333))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = dataset[:]\n",
    "\n",
    "per_fold_accuracy = torch.zeros(len(cv_trainer.fold_manager))\n",
    "with torch.no_grad():\n",
    "    for fold_idx, fold in cv_trainer.fold_manager.items():\n",
    "        model: BinaryClassifier = fold.model # type: ignore\n",
    "        model.eval()\n",
    "\n",
    "        logits = model.forward_step(all_data[\"x\"])\n",
    "        pred = (torch.sigmoid(logits) >= 0.5).long()\n",
    "        accuracy = (pred == all_data[\"y\"]).float().mean().item()\n",
    "        per_fold_accuracy[fold_idx] = accuracy\n",
    "\n",
    "per_fold_accuracy, per_fold_accuracy.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
